{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhPDWiM2GDHB"
   },
   "source": [
    "# Pytorch hands-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOdGMUFftKOT"
   },
   "outputs": [],
   "source": [
    "!rm -r ./log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLsdnbsoK_4h"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNs-o2CvGDHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from sklearn import datasets\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2MIaueiGDHH"
   },
   "source": [
    "## Fitting Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtEKHXERGDHI"
   },
   "source": [
    "### Linear model module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yGUts0OGDHJ"
   },
   "outputs": [],
   "source": [
    "# class LinearModel(nn.Module):\n",
    "#     def __init__(self, dim_input: int, dim_output: int): #, init_w: float=1.0):\n",
    "#         # TODO: see why this call is required\n",
    "#         super(LinearModel, self).__init__()\n",
    "\n",
    "#         # Initialize linear layer\n",
    "#         self.linear = nn.Linear(dim_input, dim_output)\n",
    "# #         self.linear.weight.data.uniform_(-init_w, init_w)\n",
    "# #         self.linear.bias.data.uniform_(-init_w, init_w)\n",
    "\n",
    "#     def forward(self, x: torch.Tensor):\n",
    "#         # Apply linear layer\n",
    "#         return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MV6CHujNGDHM"
   },
   "source": [
    "### Loading dataset\n",
    "\n",
    "Adapted from [scikit-learn example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXr3b-LhGDHN"
   },
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     # Load the diabetes dataset\n",
    "#     diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "#     # Use only one feature\n",
    "#     diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
    "\n",
    "#     # Split the data into training/testing sets\n",
    "#     diabetes_X_train = diabetes_X[:-20]\n",
    "#     # diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "#     # Split the targets into training/testing sets\n",
    "#     diabetes_y_train = diabetes_y[:-20]\n",
    "#     # diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "#     print(diabetes_X_train.shape)\n",
    "#     print(diabetes_y_train.shape)\n",
    "\n",
    "#     x_m = np.mean(diabetes_X_train)\n",
    "#     x_s = np.std(diabetes_X_train)\n",
    "#     xs = (diabetes_X_train - x_m) / x_s\n",
    "\n",
    "#     y_m = np.mean(diabetes_y_train)\n",
    "#     y_s = np.std(diabetes_y_train)\n",
    "#     ys = (diabetes_y_train - y_m) / y_s\n",
    "\n",
    "#     return xs, ys\n",
    "\n",
    "# xs, ys = load_data()\n",
    "# plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3uSEfVuAGDHP"
   },
   "source": [
    "### Fitting linear model by stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQnl4JgMGDHQ"
   },
   "outputs": [],
   "source": [
    "# def train(model: nn.Module, xs: np.ndarray, ys: np.ndarray, n_train_steps: int):\n",
    "#     # From numpy array to torch tensor\n",
    "#     xs = Tensor(xs)\n",
    "#     ys = Tensor(ys)\n",
    "    \n",
    "#     # Loss function: MSE loss\n",
    "#     # https://pytorch.org/docs/stable/nn.html#mseloss\n",
    "#     loss = nn.MSELoss()\n",
    "    \n",
    "#     # Optimizer: Adam\n",
    "#     # https://pytorch.org/docs/stable/optim.html#torch.optim.Adam\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "\n",
    "#     for i in range(n_train_steps):\n",
    "#         # Reset gradient\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # model.forward() is called\n",
    "#         # reshape(-1) converting shape from [422, 1] to [422]\n",
    "#         ys_pred = model(xs).reshape(-1)\n",
    "        \n",
    "#         # Loss value\n",
    "#         loss_value = loss(ys_pred, ys)\n",
    "        \n",
    "#         # Taking an optimization step\n",
    "#         # https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step\n",
    "#         loss_value.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if i % 200 == 0:\n",
    "#             print(\"Step={}, Loss = {}\".format(i, loss_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtoBv6p3GDHS"
   },
   "source": [
    "### Prediction and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkO0daSaGDHS"
   },
   "outputs": [],
   "source": [
    "# def pred_and_plot(model: nn.Module, xs: np.ndarray, ys: np.ndarray):\n",
    "#     x_min = np.min(xs)\n",
    "#     x_max = np.max(xs)\n",
    "#     xs_ = np.arange(x_min, x_max, 0.1)[:, np.newaxis]\n",
    "\n",
    "#     # Prediction\n",
    "#     ys_ = model(Tensor(xs_))\n",
    "    \n",
    "#     # From torch Tensor to numpy array\n",
    "#     # https://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html#converting-torch-tensor-to-numpy-array\n",
    "#     ys_ = ys_.detach().numpy()\n",
    "    \n",
    "#     plt.scatter(xs, ys)\n",
    "#     plt.plot(xs_, ys_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPJpPAjMGDHU"
   },
   "source": [
    "### Putting together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQKBOqHRGDHU"
   },
   "outputs": [],
   "source": [
    "# # Training\n",
    "# model = LinearModel(dim_input=1, dim_output=1)\n",
    "# xs, ys = load_data()\n",
    "# train(model, xs, ys, n_train_steps=1000)\n",
    "\n",
    "# # Prediction\n",
    "# pred_and_plot(model, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8L4-0SjfGDHW"
   },
   "source": [
    "## Monitoring loss value during training with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxvs8zCfGDHW"
   },
   "outputs": [],
   "source": [
    "# def train_with_tensorboard(model: nn.Module, optimizer: optim.Adam, \n",
    "#                            xs: np.ndarray, ys: np.ndarray,\n",
    "#                            n_train_steps: int, init_train_steps: int=0,\n",
    "#                            log_dir: str=\"./log/1\"):\n",
    "#     # Tensorboard\n",
    "#     writer = SummaryWriter(log_dir)\n",
    "\n",
    "#     # From numpy array to torch tensor\n",
    "#     xs = Tensor(xs)\n",
    "#     ys = Tensor(ys)\n",
    "    \n",
    "#     # Loss function: MSE loss\n",
    "#     # https://pytorch.org/docs/stable/nn.html#mseloss\n",
    "#     loss = nn.MSELoss()\n",
    "\n",
    "#     for i in range(init_train_steps, n_train_steps):\n",
    "#         # Reset gradient\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # model.forward() is called\n",
    "#         # reshape(-1) converting shape from [422, 1] to [422]\n",
    "#         ys_pred = model(xs).reshape(-1)\n",
    "        \n",
    "#         # Loss value\n",
    "#         loss_value = loss(ys_pred, ys)\n",
    "#         writer.add_scalar(\"loss_value\", loss_value, i)\n",
    "        \n",
    "#         # Taking an optimization step\n",
    "#         # https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step\n",
    "#         loss_value.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if i % 20 == 0:\n",
    "#             print(\"Step={}, Loss = {}\".format(i, loss_value))\n",
    "\n",
    "#     writer.close()\n",
    "\n",
    "#     return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58OY4BP7GDHX"
   },
   "outputs": [],
   "source": [
    "# # Training\n",
    "# model = LinearModel(dim_input=1, dim_output=1)\n",
    "# # https://pytorch.org/docs/stable/optim.html#torch.optim.Adam\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "# xs, ys = load_data()\n",
    "# train_with_tensorboard(model, opt, xs, ys, n_train_steps=100)\n",
    "\n",
    "# # Prediction\n",
    "# pred_and_plot(model, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijTgtSSwGDHZ"
   },
   "source": [
    "## Saving/loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eouCt7pLqBcN"
   },
   "outputs": [],
   "source": [
    "# def train_and_save(model: nn.Module, opt: optim.Adam, xs: np.ndarray,\n",
    "#                    ys: np.ndarray, n_train_steps: int):\n",
    "#     train_with_tensorboard(model, opt, xs, ys, n_train_steps,\n",
    "#                            log_dir=\"./log/2\")\n",
    "\n",
    "#     torch.save({\n",
    "#         \"model\": model.state_dict(),\n",
    "#         \"optimizer\": opt.state_dict(),\n",
    "#     }, \"./checkpoint.pt\")\n",
    "\n",
    "\n",
    "# def load_and_train(model: nn.Module, opt: optim.Adam, xs: np.ndarray,\n",
    "#                    ys: np.ndarray, n_train_steps: int, init_train_steps: int):\n",
    "#     checkpoint = torch.load(\"./checkpoint.pt\")\n",
    "\n",
    "#     model.load_state_dict(checkpoint[\"model\"])\n",
    "#     opt.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "#     train_with_tensorboard(model, opt, xs, ys, n_train_steps, init_train_steps,\n",
    "#                            log_dir=\"./log/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocaFZjTurTju"
   },
   "outputs": [],
   "source": [
    "# # Training, saving and loading model\n",
    "# model = LinearModel(dim_input=1, dim_output=1)\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "\n",
    "# xs, ys = load_data()\n",
    "\n",
    "# train_and_save(model, opt, xs, ys, n_train_steps=20)\n",
    "# load_and_train(model, opt, xs, ys, 100, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIKQwxO-GDHb"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./log"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "index.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "index.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jhPDWiM2GDHB"
      },
      "source": [
        "# Pytorch hands-on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JOdGMUFftKOT",
        "colab": {}
      },
      "source": [
        "!rm -r ./log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cLsdnbsoK_4h",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pLF8KnPQmCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tNs-o2CvGDHC",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "from sklearn import datasets\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N2MIaueiGDHH"
      },
      "source": [
        "## Fitting Linear model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wtEKHXERGDHI"
      },
      "source": [
        "### Linear model module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5yGUts0OGDHJ",
        "colab": {}
      },
      "source": [
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, dim_input: int, dim_output: int): #, init_w: float=1.0):\n",
        "        # TODO: see why this call is required\n",
        "        super(LinearModel, self).__init__()\n",
        "\n",
        "        # Initialize linear layer\n",
        "        self.linear = nn.Linear(dim_input, dim_output)\n",
        "#         self.linear.weight.data.uniform_(-init_w, init_w)\n",
        "#         self.linear.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # Apply linear layer\n",
        "        return self.linear(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZaW8XiCPzMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinearModel(1, 1)\n",
        "writer = SummaryWriter(\"./log/1\")\n",
        "writer.add_graph(model, (Tensor([[1.0]])))\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MV6CHujNGDHM"
      },
      "source": [
        "### Loading dataset\n",
        "\n",
        "Adapted from [scikit-learn example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)\n",
        "\n",
        "* Reshape input tensor (`np.newaxis`)\n",
        "  * The model needs inputs to have two dimensions for minibatching and the representing the input size, i.e., the number of elements of each input\n",
        "* Normalization for making the mean of the points to 0 and the std to 1, both inputs and outputs\n",
        "  * NOTE: This dataset seems to be normalized beforehand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXr3b-LhGDHN",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    # Dataset description\n",
        "    data = datasets.load_diabetes()\n",
        "    print(data.DESCR)\n",
        "    print()\n",
        "\n",
        "    # Feature name\n",
        "    ix_feature = 2\n",
        "    print(\"Explanatory variable: {}\".format(data.feature_names[ix_feature]))\n",
        "    \n",
        "    # Load the diabetes dataset\n",
        "    diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "    # Reshape input tensor\n",
        "    # (442, 10) -> (442, 1)\n",
        "    diabetes_X = diabetes_X[:, np.newaxis, ix_feature]\n",
        "\n",
        "    # Split the data into training/testing sets\n",
        "    diabetes_X_train = diabetes_X[:-20]\n",
        "    # diabetes_X_test = diabetes_X[-20:]\n",
        "\n",
        "    # Split the targets into training/testing sets\n",
        "    diabetes_y_train = diabetes_y[:-20]\n",
        "    # diabetes_y_test = diabetes_y[-20:]\n",
        "\n",
        "    print(diabetes_X_train.shape)\n",
        "    print(diabetes_y_train.shape)\n",
        "\n",
        "    # Normalization\n",
        "    x_m = np.mean(diabetes_X_train)\n",
        "    x_s = np.std(diabetes_X_train)\n",
        "    xs = (diabetes_X_train - x_m) / x_s\n",
        "\n",
        "    y_m = np.mean(diabetes_y_train)\n",
        "    y_s = np.std(diabetes_y_train)\n",
        "    ys = (diabetes_y_train - y_m) / y_s\n",
        "\n",
        "    return xs, ys\n",
        "\n",
        "xs, ys = load_data()\n",
        "plt.scatter(xs, ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3uSEfVuAGDHP"
      },
      "source": [
        "### Fitting linear model by stochastic gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LQnl4JgMGDHQ",
        "colab": {}
      },
      "source": [
        "def train(model: nn.Module, xs: np.ndarray, ys: np.ndarray, n_train_steps: int):\n",
        "    # From numpy array to torch tensor\n",
        "    xs = Tensor(xs)\n",
        "    ys = Tensor(ys)\n",
        "    \n",
        "    # Loss function: MSE loss\n",
        "    # https://pytorch.org/docs/stable/nn.html#mseloss\n",
        "    loss = nn.MSELoss()\n",
        "    \n",
        "    # Optimizer: Adam\n",
        "    # https://pytorch.org/docs/stable/optim.html#torch.optim.Adam\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
        "\n",
        "    for i in range(n_train_steps):\n",
        "        # Reset gradient\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # model.forward() is called\n",
        "        # reshape(-1) converting shape from [422, 1] to [422]\n",
        "        ys_pred = model(xs).reshape(-1)\n",
        "        \n",
        "        # Loss value\n",
        "        loss_value = loss(ys_pred, ys)\n",
        "        \n",
        "        # Taking an optimization step\n",
        "        # https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 200 == 0:\n",
        "            print(\"Step={}, Loss = {}\".format(i, loss_value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QtoBv6p3GDHS"
      },
      "source": [
        "### Prediction and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FkO0daSaGDHS",
        "colab": {}
      },
      "source": [
        "def pred_and_plot(model: nn.Module, xs: np.ndarray, ys: np.ndarray):\n",
        "    x_min = np.min(xs)\n",
        "    x_max = np.max(xs)\n",
        "    xs_ = np.arange(x_min, x_max, 0.1)[:, np.newaxis]\n",
        "\n",
        "    # Prediction\n",
        "    ys_ = model(Tensor(xs_))\n",
        "    \n",
        "    # From torch Tensor to numpy array\n",
        "    # https://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html#converting-torch-tensor-to-numpy-array\n",
        "    ys_ = ys_.detach().numpy()\n",
        "    \n",
        "    plt.scatter(xs, ys)\n",
        "    plt.plot(xs_, ys_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FPJpPAjMGDHU"
      },
      "source": [
        "### Putting together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qQKBOqHRGDHU",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "model = LinearModel(dim_input=1, dim_output=1)\n",
        "xs, ys = load_data()\n",
        "train(model, xs, ys, n_train_steps=1000)\n",
        "\n",
        "# Prediction\n",
        "pred_and_plot(model, xs, ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8L4-0SjfGDHW"
      },
      "source": [
        "## Monitoring loss value during training with Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mxvs8zCfGDHW",
        "colab": {}
      },
      "source": [
        "def train_with_tensorboard(model: nn.Module, optimizer: optim.Adam, \n",
        "                           xs: np.ndarray, ys: np.ndarray,\n",
        "                           n_train_steps: int, init_train_steps: int=0,\n",
        "                           log_dir: str=\"./log/1\"):\n",
        "    # Tensorboard\n",
        "    writer = SummaryWriter(log_dir)\n",
        "\n",
        "    # From numpy array to torch tensor\n",
        "    xs = Tensor(xs)\n",
        "    ys = Tensor(ys)\n",
        "    \n",
        "    # Loss function: MSE loss\n",
        "    # https://pytorch.org/docs/stable/nn.html#mseloss\n",
        "    loss = nn.MSELoss()\n",
        "\n",
        "    for i in range(init_train_steps, n_train_steps):\n",
        "        # Reset gradient\n",
        "        # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
        "        # https://discuss.pytorch.org/t/model-zero-grad-or-optimizer-zero-grad/28426/6\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # model.forward() is called\n",
        "        # reshape(-1) converting shape from [422, 1] to [422]\n",
        "        ys_pred = model(xs).reshape(-1)\n",
        "        \n",
        "        # Loss value\n",
        "        loss_value = loss(ys_pred, ys)\n",
        "        writer.add_scalar(\"loss_value\", loss_value, i)\n",
        "        \n",
        "        # Taking an optimization step\n",
        "        # https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 20 == 0:\n",
        "            print(\"Step={}, Loss = {}\".format(i, loss_value))\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    return model, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "58OY4BP7GDHX",
        "colab": {}
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "# https://pytorch.org/docs/stable/notes/randomness.html\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Training\n",
        "model = LinearModel(dim_input=1, dim_output=1)\n",
        "# https://pytorch.org/docs/stable/optim.html#torch.optim.Adam\n",
        "opt = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
        "xs, ys = load_data()\n",
        "train_with_tensorboard(model, opt, xs, ys, n_train_steps=100)\n",
        "\n",
        "# Prediction\n",
        "pred_and_plot(model, xs, ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ijTgtSSwGDHZ"
      },
      "source": [
        "## Saving/loading trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eouCt7pLqBcN",
        "colab": {}
      },
      "source": [
        "def train_and_save(model: nn.Module, opt: optim.Adam, xs: np.ndarray,\n",
        "                   ys: np.ndarray, n_train_steps: int):\n",
        "    train_with_tensorboard(model, opt, xs, ys, n_train_steps,\n",
        "                           log_dir=\"./log/2\")\n",
        "\n",
        "    torch.save({\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": opt.state_dict(),\n",
        "    }, \"./checkpoint.pt\")\n",
        "\n",
        "\n",
        "def load_and_train(model: nn.Module, opt: optim.Adam, xs: np.ndarray,\n",
        "                   ys: np.ndarray, n_train_steps: int, init_train_steps: int):\n",
        "    checkpoint = torch.load(\"./checkpoint.pt\")\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model\"])\n",
        "    opt.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    train_with_tensorboard(model, opt, xs, ys, n_train_steps, init_train_steps,\n",
        "                           log_dir=\"./log/3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ocaFZjTurTju",
        "colab": {}
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "# https://pytorch.org/docs/stable/notes/randomness.html\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Train and save internal states of the model and the optimizer\n",
        "model = LinearModel(dim_input=1, dim_output=1)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
        "xs, ys = load_data()\n",
        "train_and_save(model, opt, xs, ys, n_train_steps=20)\n",
        "\n",
        "# Make sure that loading model works for checkpointing\n",
        "model_ = LinearModel(dim_input=1, dim_output=1)\n",
        "opt_ = optim.Adam(model_.parameters(), lr=1e-2, amsgrad=True)\n",
        "load_and_train(model_, opt_, xs, ys, 100, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
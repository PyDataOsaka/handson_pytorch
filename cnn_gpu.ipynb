{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyDataOsaka/handson_pytorch/blob/master/cnn_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6O_gWw0IdDY7"
      },
      "source": [
        "# Pytorch hands-on (CNN)\n",
        "\n",
        "Adapted from [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3K_aYfDr4tGR",
        "colab": {}
      },
      "source": [
        "!rm -r ./log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RdvMzk4P8L0h",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UhEIDdMo8b1y",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir ./log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1pntTjNDey8Y",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KLmU-d73dMYz"
      },
      "source": [
        "## Load image data\n",
        "\n",
        "* [CIFAR10](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar) dataset\n",
        "* Compose data preprocesses\n",
        "  * Convert from numpy to pytorch Tensor (`transforms.ToTensor()`)\n",
        "  * Channel-wise normalization (`transforms.Normalize()`)\n",
        "    * https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize\n",
        "* Make `DataLoader` for automatic minibatching\n",
        "  * https://pytorch.org/docs/stable/data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PN8KxRCeBM_",
        "colab": {}
      },
      "source": [
        "def get_data(batch_size: int=64):\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                          download=True, transform=transform)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                         download=True, transform=transform)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                           shuffle=False, num_workers=2)\n",
        "\n",
        "  classes = ('plane', 'car', 'bird', 'cat',\n",
        "             'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "  \n",
        "  return trainloader, testloader, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rmRYt4I2eqej"
      },
      "source": [
        "## Define CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAAAbBHOeuYg",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv1(x)))\n",
        "    x = self.pool2(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcAZj5yORNUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net()\n",
        "trainloader, _, _ = get_data()\n",
        "writer = SummaryWriter(\"./log/1\")\n",
        "writer.add_graph(model, (trainloader.__iter__().__next__()[0]))\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y5WAQqDOvHlG"
      },
      "source": [
        "## Define functions\n",
        "\n",
        "* Transfer arrays from cpu to gpu\n",
        "  * `model.to(device)`, `data[0].to(device), data[1].to(device)`\n",
        "  * https://pytorch.org/docs/stable/notes/cuda.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "avMEYcqivKqu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gf9a2nfwdbKz",
        "colab": {}
      },
      "source": [
        "def train(model: nn.Module, trainloader, log_dir: str, device=\"cpu\"):\n",
        "  model.to(device)\n",
        "\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  writer = SummaryWriter(log_dir)\n",
        "  running_loss = 0.0\n",
        "  prev_time = time()\n",
        "  n_minibatches = 0\n",
        "\n",
        "  for epoch in range(4):\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      opt.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss_value = loss(outputs, labels)\n",
        "      loss_value.backward()\n",
        "      opt.step()\n",
        "\n",
        "      writer.add_scalar(\"loss_value\", loss_value, n_minibatches)\n",
        "      n_minibatches += 1\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss_value.item()\n",
        "      if i % 100 == 99:    # print every 100 mini-batches\n",
        "        print('[{}, {:5d}] loss: {:.3f}, elapsed time: {:.1f} [sec]'.format(\n",
        "              epoch + 1, i + 1, running_loss / 100, time() - prev_time))\n",
        "        running_loss = 0.0\n",
        "        prev_time = time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hUF2KlM6vOJ9"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K38G8Rf4vQbT",
        "colab": {}
      },
      "source": [
        "def evaluate(model: nn.Module, testloader, device: str=\"cpu\"):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G02jF23HdRUL"
      },
      "source": [
        "## Training and evaluation of the model on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktGinhnw4PKo",
        "colab": {}
      },
      "source": [
        "trainloader, testloader, classes = get_data()\n",
        "model = Net()\n",
        "\n",
        "train(model, trainloader, \"./log/1\")\n",
        "torch.save({\n",
        "    \"model\": model.state_dict(),\n",
        "}, \"./model_cpu.pt\")\n",
        "\n",
        "evaluate(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wZkUvJ0CQcvQ"
      },
      "source": [
        "## Training and evaluation of the model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQLWYaBaJ9Ww",
        "colab": {}
      },
      "source": [
        "trainloader, testloader, classes = get_data()\n",
        "model = Net()\n",
        "\n",
        "train(model, trainloader, \"./log/2\", \"cuda\")\n",
        "torch.save({\n",
        "    \"model\": model.state_dict(),\n",
        "}, \"./model_gpu.pt\")\n",
        "\n",
        "evaluate(model, testloader, \"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6HgJkSiX3lK7"
      },
      "source": [
        "## Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xi2DijWx3onS",
        "colab": {}
      },
      "source": [
        "trainloader, testloader, classes = get_data()\n",
        "model = Net()\n",
        "\n",
        "checkpoint = torch.load(\"./model_gpu.pt\")\n",
        "model.load_state_dict(checkpoint[\"model\"])\n",
        "model.to(\"cuda\")\n",
        "\n",
        "evaluate(model, testloader, \"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sdLiZ60F4Lfq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
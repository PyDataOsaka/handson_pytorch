{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN02H4lpsGRazEte1EPvpbM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyDataOsaka/handson_pytorch/blob/master/cnn_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O_gWw0IdDY7",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch hands-on (CNN on TPU)\n",
        "\n",
        "Adapted from [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K_aYfDr4tGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r ./log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdvMzk4P8L0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhEIDdMo8b1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir ./log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KSsPAlrfvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRKsehbr6fNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"XLA_USE_BF16\"] = \"1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIOoNPnZrk9A",
        "colab_type": "text"
      },
      "source": [
        "## Installing Pytorch/XLA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmyGzNV9sPWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pntTjNDey8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLmU-d73dMYz",
        "colab_type": "text"
      },
      "source": [
        "## Load image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PN8KxRCeBM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(batch_size: int=64):\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                          download=True, transform=transform)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                         download=True, transform=transform)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                           shuffle=False, num_workers=2)\n",
        "\n",
        "  classes = ('plane', 'car', 'bird', 'cat',\n",
        "             'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "  \n",
        "  return trainloader, testloader, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmRYt4I2eqej",
        "colab_type": "text"
      },
      "source": [
        "## CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAAAbBHOeuYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5).bfloat16()\n",
        "    self.pool = nn.MaxPool2d(2, 2).bfloat16()\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5).bfloat16()\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120).bfloat16()\n",
        "    self.fc2 = nn.Linear(120, 84).bfloat16()\n",
        "    self.fc3 = nn.Linear(84, 10).bfloat16()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5WAQqDOvHlG",
        "colab_type": "text"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avMEYcqivKqu",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf9a2nfwdbKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_tpu(model: nn.Module, trainloader, log_dir: str, device):\n",
        "  model.to(device)\n",
        "\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  writer = SummaryWriter(log_dir)\n",
        "  running_loss = 0.0\n",
        "  prev_time = time()\n",
        "  n_minibatches = 0\n",
        "\n",
        "  for epoch in range(4):\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      opt.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss_value = loss(outputs, labels)\n",
        "      loss_value.backward()\n",
        "      # opt.step() # For CPU/GPU\n",
        "      xm.optimizer_step(opt, barrier=True)  # Note: Cloud TPU-specific code!\n",
        "\n",
        "      writer.add_scalar(\"loss_value\", loss_value, n_minibatches)\n",
        "      n_minibatches += 1\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss_value.item()\n",
        "      if i % 100 == 99:    # print every 100 mini-batches\n",
        "        print('[{}, {:5d}] loss: {:.3f}, elapsed time: {:.1f} [sec]'.format(\n",
        "              epoch + 1, i + 1, running_loss / 2000, time() - prev_time))\n",
        "        running_loss = 0.0\n",
        "        prev_time = time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUF2KlM6vOJ9",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K38G8Rf4vQbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model: nn.Module, testloader, device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZkUvJ0CQcvQ",
        "colab_type": "text"
      },
      "source": [
        "## Training and evaluation of the model on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQLWYaBaJ9Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader, testloader, classes = get_data()\n",
        "model = Net()\n",
        "\n",
        "dev = xm.xla_device()\n",
        "\n",
        "train_tpu(model, trainloader, \"./log/2\", dev)\n",
        "evaluate(model, testloader, dev)\n",
        "\n",
        "model.to(\"cpu\")\n",
        "torch.save({\n",
        "    \"model\": model.state_dict(),\n",
        "}, \"./model_tpu.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HgJkSiX3lK7",
        "colab_type": "text"
      },
      "source": [
        "## Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi2DijWx3onS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader, testloader, classes = get_data()\n",
        "model = Net()\n",
        "\n",
        "dev = xm.xla_device()\n",
        "\n",
        "checkpoint = torch.load(\"./model_tpu.pt\")\n",
        "model.load_state_dict(checkpoint[\"model\"])\n",
        "model.to(dev)\n",
        "\n",
        "evaluate(model, testloader, dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdLiZ60F4Lfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}